<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>945e91e0477248a5a4ad0dc3c90a35e8</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" data-colab_type="text" id="view-in-github">
<p><a href="https://colab.research.google.com/github/AnuR1234/GNN/blob/main/%E2%80%9CAutoencoder_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
</div>
<div class="cell markdown" id="Lsw8YKU7O_Yf">
<p>##Task 1</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:449}"
id="0GvmyEhPuxJa" data-outputId="55df2c68-cd4c-40a8-fb15-23f92479bf37">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn, optim</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.autograd <span class="im">import</span> Variable</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, datasets</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> save_image</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> autoencoder(nn.Module):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,input_size,bottleneck_size,hidden_size,layers):</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(autoencoder, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        encoder_layers <span class="op">=</span> []</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layers<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            encoder_layers.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            encoder_layers.append(nn.ReLU())</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.Sequential(nn.Linear(input_size,hidden_size),nn.ReLU(),<span class="op">*</span>encoder_layers,nn.Linear(hidden_size,bottleneck_size))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        decoder_layers <span class="op">=</span> []</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layers<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>            decoder_layers.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            decoder_layers.append(nn.ReLU())</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decoder <span class="op">=</span> nn.Sequential(nn.Linear(bottleneck_size,hidden_size),nn.ReLU(),<span class="op">*</span>decoder_layers,nn.Linear(hidden_size,input_size))</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        encode <span class="op">=</span> <span class="va">self</span>.encoder(x)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        decode <span class="op">=</span> <span class="va">self</span>.decoder(encode)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>  encode,decode</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> decode_function(<span class="va">self</span>,code):</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.decoder(code)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training set and testing</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.FloatTensor(X)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co"># convert it to tensor</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> TensorDataset(X, X)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">#Set parameters</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>hidden_size<span class="op">=</span><span class="dv">30</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>layers<span class="op">=</span><span class="dv">3</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> autoencoder(input_size, bottleneck_size,hidden_size,layers)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">#Train</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>loss_list<span class="op">=</span>[]</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>state_dicts <span class="op">=</span> {}<span class="co">#Storage parameters</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>        inputs, _ <span class="op">=</span> data</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>        _,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>    loss_list.append(loss.item())</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot loss</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(num_epochs), loss_list, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/c660a8f606c08b020fd8b83d34bdbdfa699c19c3.png" /></p>
</div>
</div>
<div class="cell markdown" id="doDWRDFPe0f7">
<p>#Comment: Before we find the best hyperparameters, we just randomly
choose hyperparameters to test whether this model works. Then we do the
reconstruction and visualize the result.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:452}"
id="zJJ9Nmintxs2" data-outputId="2b2843a7-55ff-4ce9-a249-33951a918222">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reconstruction</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  code,reconstructed_data <span class="op">=</span> model(X)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Original Data vs. Reconstructed Data&#39;</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/3c21037318bcb80503504e33c71d2e13719e2657.png" /></p>
</div>
</div>
<div class="cell markdown" id="5-oElhg5N_yJ">
<p>#1.1 Investigate systematically the effect of the hyperparameters.
Report your findings in suitable plots (e.g. test set reconstruction
error as a function of hyperparameters, and reconstructed vs. original
points for selected settings). Make sure that all plots are properly
labeled (title, axis labels, legend). Comment on your findings.</p>
</div>
<div class="cell code" id="ncq_S4tCmzw5">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Train model with different hidden size and layers</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_size <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>hidden_size_list<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">10</span>,<span class="dv">101</span>,<span class="dv">10</span>))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>layers_list<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">11</span>))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>Loss <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layers <span class="kw">in</span> layers_list:</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> hidden_size <span class="kw">in</span> hidden_size_list:</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> autoencoder(input_size,bottleneck_size,hidden_size,layers)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    training_set <span class="op">=</span> torch.FloatTensor(X[:data_size,:])</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> TensorDataset(training_set, training_set)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    Loss_epoch <span class="op">=</span> []</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>          inputs,_ <span class="op">=</span> data</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>          _,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>          loss <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>          optimizer.zero_grad()</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>          loss.backward()</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>          optimizer.step()</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>      Loss_epoch.append(loss.item())</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    Loss[layers<span class="op">-</span><span class="dv">1</span>].append(Loss_epoch)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="OHKFrQu6rc-X" data-outputId="d352bde0-88c6-452c-9016-8adc5072948b">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data_size <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">5</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, hidden_size <span class="kw">in</span> <span class="bu">enumerate</span>(hidden_size_list):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>      ax.plot(<span class="bu">range</span>(num_epochs), Loss[i][j], label<span class="op">=</span><span class="ss">f&quot;Size of Hidden Layer: </span><span class="sc">{</span>hidden_size<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="st">&#39;small&#39;</span>, bbox_to_anchor<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Hidden Layers=&#39;</span><span class="op">+</span><span class="bu">str</span>(layers_list[i]))</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.5</span>, top<span class="op">=</span><span class="dv">3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.6</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/d78873b830a3b8680580864e5bc2094555f9f065.png" /></p>
</div>
</div>
<div class="cell markdown" id="WKZavDAe1Bsx">
<p>#Comment First, we explored the effect of the number and the size of
the hidden layers on the model. We set different sizes of hidden layers
in 10 different number of hidden layers respectively. Observing the
above graphs, there are the following conclusions:</p>
<p>1.The size of the hidden layers has a greater impact on the model
than their number.Even with only one hidden layer, the loss can converge
to nearly 0.1.But when the size is only 10, the loss is still very high
with 10 hidden layers.</p>
<p>2.If the size of hidden layers is not too small, the loss will be
stable after 40 epochs in every situation.But it still decreases
slightly when the size and the number of hidden layers are big, we
decide to choose epochs=100 in next models.</p>
<p>3.A strange thing is that when the size of hidden layer is 10, this
autoencoder model works worse with more hidden layers.</p>
<p>4.When the size of hidden layer is big enough, the number of hidden
layers has little impact on the model. So we just choose
hidden_size=100,layers=5 in all the next models.</p>
<p>Then we explore how the size of data size influences the model.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:564}"
id="sgOur-TR69HZ" data-outputId="655ca93a-206d-4c0e-f724-06166d4f6bb1">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Train model with different data size</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data_size <span class="op">=</span> [<span class="dv">100</span>,<span class="dv">300</span>,<span class="dv">500</span>,<span class="dv">1000</span>]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>hidden_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>layers<span class="op">=</span><span class="dv">5</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>Loss <span class="op">=</span> []</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> size <span class="kw">in</span> data_size:</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> autoencoder(input_size,bottleneck_size,hidden_size,layers)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    training_set <span class="op">=</span> torch.FloatTensor(X[:size,:])</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> TensorDataset(training_set, training_set)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    Loss_epoch <span class="op">=</span> []</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>          inputs,_ <span class="op">=</span> data</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>          _,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>          loss <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>          optimizer.zero_grad()</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>          loss.backward()</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>          optimizer.step()</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>      Loss_epoch.append(loss.item())</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>      torch.save(model.state_dict(),<span class="st">&#39;model&#39;</span><span class="op">+</span><span class="bu">str</span>(size) <span class="op">+</span><span class="st">&#39;-&#39;</span><span class="op">+</span> <span class="bu">str</span>(epoch<span class="op">+</span><span class="dv">1</span>) <span class="op">+</span><span class="st">&#39;.pth&#39;</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    Loss.append(Loss_epoch)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, size <span class="kw">in</span> <span class="bu">enumerate</span>(data_size):</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(num_epochs), Loss[i], label<span class="op">=</span><span class="ss">f&quot;Sample Size: </span><span class="sc">{</span>size<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39; Loss for Different Sample Sizes&#39;</span>)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/fe7abd85efc573c962627975ef4168884ec916e0.png" /></p>
</div>
</div>
<div class="cell markdown" id="onv9dAbh75jQ">
<p>#Comment As expected, the loss will decrease when the size of
training set increases.</p>
<p>Then we visualize the reconstruction in different epochs.</p>
</div>
<div class="cell code" id="bBwRrMZl_Mno">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#visualization</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualization(epoch):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  loaded_epoch <span class="op">=</span> epoch</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>      ax.scatter(X[<span class="dv">0</span>:data_size[i],<span class="dv">0</span>],X[<span class="dv">0</span>:data_size[i],<span class="dv">1</span>],label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>      <span class="co">#Load parameters of autoencoder model</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>      loaded_state_dict <span class="op">=</span> torch.load(<span class="st">&#39;model&#39;</span> <span class="op">+</span><span class="bu">str</span>(data_size[i]) <span class="op">+</span><span class="st">&#39;-&#39;</span><span class="op">+</span> <span class="bu">str</span>(loaded_epoch) <span class="op">+</span><span class="st">&#39;.pth&#39;</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>      model.load_state_dict(loaded_state_dict)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>      training_set <span class="op">=</span> torch.FloatTensor(X[<span class="dv">0</span>:data_size[i],:])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>      <span class="co">#Reconstruction</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        code,reconstructed_data <span class="op">=</span> model(training_set)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>      ax.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>      ax.legend()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>      ax.set_title(<span class="st">&#39;Data Set Size=&#39;</span><span class="op">+</span><span class="bu">str</span>(data_size[i]))</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.2</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  fig.suptitle(<span class="st">&#39;Epoch=&#39;</span><span class="op">+</span><span class="bu">str</span>(loaded_epoch), y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="K5vwxHcVAIYI" data-outputId="c509fb3b-70d8-446a-dac6-f0fb3c17dbca">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>visualization(<span class="dv">10</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/0fe2925179df9a5fd6de8b31d5cbfd3b29228f4d.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="UIN6_y3rAfCN" data-outputId="72ce1916-e212-4354-98ce-09368d53a4c6">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>visualization(<span class="dv">50</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/d0aa04d9e1ad085207ae5132037336ff2547acd6.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="b_ihL3udAOyi" data-outputId="ab9d41b2-ccd2-4c43-ddec-39acbb3172e3">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>visualization(<span class="dv">100</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/bb594d1d772371ca1484efdeb87676c6da4e9ab3.png" /></p>
</div>
</div>
<div class="cell markdown" id="RKj4n2Wd8m4a">
<p>#Comment: With a small data set (size=100), this model still can't
learn the structure of data after 100 epochs.When we increases data set
to 1000, it can reconstruct very well, and can even capture basic
structure of the data in only 10 epochs. So the size of training data
matters a lot as expected.</p>
</div>
<div class="cell markdown" id="_9Mpd14jNylp">
<p>#1.2 For the best hyperparameter settings you found, investigate how
much the reconstruction varies when you repeat training with the same or
diffeerent datasets. Comment on your observations.</p>
</div>
<div class="cell code" id="4iqank5H-vm3">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>num_epochs<span class="op">=</span><span class="dv">100</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>hidden_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>layers<span class="op">=</span><span class="dv">5</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>data_list<span class="op">=</span>[]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>reconstructed_list<span class="op">=</span>[]</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    X, _ <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    data_list.append(X)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> torch.FloatTensor(X)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> TensorDataset(X, X)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>          inputs,_ <span class="op">=</span> data</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>          _,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>          loss <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>          optimizer.zero_grad()</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>          loss.backward()</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>          optimizer.step()</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Reconstruction</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>      _,reconstructed_data <span class="op">=</span> model(X)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    reconstructed_list.append(reconstructed_data)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="mfLtmxk_D7YZ" data-outputId="1fc0cd93-925f-4ba0-eff4-09ec57a3ce77">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    ax.scatter(data_list[i][:,<span class="dv">0</span>],data_list[i][:,<span class="dv">1</span>],label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    ax.scatter(reconstructed_list[i][:,<span class="dv">0</span>],reconstructed_list[i][:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Data Set &#39;</span><span class="op">+</span><span class="bu">str</span>(i<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.2</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Repeat training with different data sets&#39;</span>, y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/d63e3bb04b56483600a37ccdea282298c152c5ef.png" /></p>
</div>
</div>
<div class="cell markdown" id="SwYjsJ3uFjhW">
<p>#Comment With the hyperparameters we choose, we can see the model is
robust.</p>
</div>
<div class="cell markdown" id="WJZEw_sLNQh-">
<p>#1.3 Create and visualize a histogram of the code distribution. Fit a
Gaussian mixture model to the code distribution and use it to sample
synthetic data. Comment on the quality of the generated data.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:865}"
id="LYYY5KnqI5DF" data-outputId="e73298ec-755a-4d8e-edc6-27f6879b19d9">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#1.3</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.FloatTensor(data_list[<span class="dv">3</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  code,reconstructed_data <span class="op">=</span> model(X)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Use GMM to fit code</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>n_components<span class="op">=</span><span class="dv">30</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>gmm<span class="op">=</span>GaussianMixture( n_components,random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>gmm.fit(code)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">7</span>, <span class="dv">3</span>, <span class="dv">1000</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>logprob <span class="op">=</span> gmm.score_samples(x.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>responsibilities <span class="op">=</span> gmm.predict_proba(x.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> np.exp(logprob)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>pdf_individual <span class="op">=</span> responsibilities <span class="op">*</span> pdf[:, np.newaxis]</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot histogram</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>sns.histplot(code, bins<span class="op">=</span><span class="dv">50</span>, label<span class="op">=</span><span class="st">&#39;code&#39;</span>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>plt.xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">7</span>,<span class="dv">3</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Histogram of the Code Distribution&#39;</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf, <span class="st">&#39;-k&#39;</span>, label<span class="op">=</span><span class="st">&#39;GMM&#39;</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>plt.xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">7</span>,<span class="dv">3</span>)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/65897b47e4a83b15148faeeb593118f94399e9bf.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/2a037dca5ca57f331d72ac75e1900fafdedad19b.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:765}"
id="8SykrGvEEmNf" data-outputId="73447898-c88d-46bc-a48a-b2293a69bb12">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Visualizing the generated samples from GMM with different components</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>components_list<span class="op">=</span>[<span class="dv">2</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">50</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#fitting GMM</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  gmm<span class="op">=</span>GaussianMixture( components_list[i],random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  gmm.fit(code)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Generating samples from GMM</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  n_samples<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  GMM_samples, _ <span class="op">=</span> gmm.sample(n_samples)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  GMM_samples <span class="op">=</span> torch.FloatTensor(GMM_samples)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#decoding code from samples generated from GMM</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    reconstructed_data <span class="op">=</span> model.decode_function(GMM_samples)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  ax.scatter(data_list[<span class="dv">3</span>][:, <span class="dv">0</span>], data_list[<span class="op">-</span><span class="dv">1</span>][:, <span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>  ax.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Samples from GMM&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  ax.legend()</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>  ax.set_title(<span class="st">&#39;  GMM with &#39;</span><span class="op">+</span><span class="bu">str</span>(components_list[i])<span class="op">+</span><span class="st">&#39; Components&#39;</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.4</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Original Data vs Samples from GMM&#39;</span>, y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/ce2309ec4a5664f28927c6c475cbc7b1551c5c29.png" /></p>
</div>
</div>
<div class="cell markdown" id="_lrX-iwCL9Qm">
<p>#Comment: Since the data set is two moons, we naturally thought a GMM
with 2 components would be the best. But it didn't turn out that way.20
is a better choice.</p>
</div>
<div class="cell markdown" id="9v5scYqMNIDL">
<p>#1.4 Check if the autoencoder still works (without retraining!) on a
test set at noise level 0.2.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:452}"
id="SZNiLIUhzQAd" data-outputId="1c755299-f662-4ce3-ec63-6d5ccdcdfd8d">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#1.4</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>loaded_epoch <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>n_samples<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>Y, _ <span class="op">=</span> make_moons(n_samples, noise<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> torch.FloatTensor(Y)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  _,reconstructed_data <span class="op">=</span> model(test_data)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_data[:, <span class="dv">0</span>], test_data[:, <span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Test Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Test Data (noise=0.2) vs. Reconstructed Data&#39;</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/fe5dca35c1e5c0c626770ba3f9d94a58a66c8d63.png" /></p>
</div>
</div>
<div class="cell markdown" id="losufAgsNkKV">
<p>#Comment: It still works, but not good.</p>
</div>
<div class="cell markdown" id="zfuV_3ZhM5ps">
<p>#1.5 Train an autoencoder with a training set at noise level 0.2 and
comment on how the geometry of the reconstructed set changes.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:452}"
id="Ax440BIFzihX" data-outputId="e082fc84-be47-43a1-ef33-09e5b2bbe1a0">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>Y, _ <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">1000</span>, noise<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.FloatTensor(Y)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> TensorDataset(Y, Y)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>hidden_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>layers<span class="op">=</span><span class="dv">5</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> autoencoder(input_size,bottleneck_size,hidden_size,layers)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        inputs, _ <span class="op">=</span> data</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>        _,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="co">#reconstruction</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>  _,reconstructed_data <span class="op">=</span> model(Y)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>plt.scatter(Y[:, <span class="dv">0</span>], Y[:, <span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Data Set with noise=0.2&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Data Set vs. Reconstructed Data&#39;</span>)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/896ddb2f6df41b4e4f9ee42623005cfa5b06805e.png" /></p>
</div>
</div>
<div class="cell markdown" id="d4DuUGH9OJsn">
<p>#Comment: It can still capture the basic structure of data, but the
reconstructed set is not as smooth as former one (noise=0.1).</p>
</div>
<div class="cell markdown" id="eTJJlRXRMjND">
<p>#Task 2</p>
</div>
<div class="cell code" id="NlTPmMuI0z_m">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Redefine the MMD function we defined at last assignment with tensor form</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> squared_distances(X, Y):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the squared Euclidean distances between each pair of points in the two datasets X and Y.</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">    :param X: Array of shape (n_samples_X, n_features).</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">    :param Y: Array of shape (n_samples_Y, n_features).</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: Matrix of shape (n_samples_X, n_samples_Y) where each element represents the squared distance.</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Expand the squares of X and Y</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    X_square <span class="op">=</span> torch.<span class="bu">sum</span>(X<span class="op">**</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    Y_square <span class="op">=</span> torch.<span class="bu">sum</span>(Y<span class="op">**</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the squared distances</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    squared_dist <span class="op">=</span> X_square  <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> torch.matmul(X, Y.t()) <span class="op">+</span> Y_square.t()</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> squared_dist</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> se_kernel_custom(X, Y, gamma<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the Radial Basis Function (RBF) kernel (squared exponential) between each pair of points in X and Y.</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co">    :param X: First dataset.</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="co">    :param Y: Second dataset.</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co">    :param gamma: Gamma parameter for the RBF kernel. If None, it&#39;s set to 1/n_features.</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: RBF kernel matrix.</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> gamma <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        gamma <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> X.shape[<span class="dv">1</span>]  <span class="co"># 1/n_features</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    sq_dists <span class="op">=</span> squared_distances(X, Y)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.exp(<span class="op">-</span>gamma <span class="op">*</span> sq_dists)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_mmd(kernel_XX, kernel_YY, kernel_XY):</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the MMD value from the kernel matrices.</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="co">    :param kernel_XX: Kernel matrix among samples in X.</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="co">    :param kernel_YY: Kernel matrix among samples in Y.</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="co">    :param kernel_XY: Kernel matrix between samples in X and Y.</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: MMD value.</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    mmd_square <span class="op">=</span> torch.mean(kernel_XX) <span class="op">+</span> torch.mean(kernel_YY) <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> torch.mean(kernel_XY)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.sqrt(mmd_square)  <span class="co"># Return the square root to get MMD</span></span></code></pre></div>
</div>
<div class="cell code" id="Nk6r3ocOi7uS">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Autoencoder model with different weights</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn, optim</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.autograd <span class="im">import</span> Variable</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, datasets</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> save_image</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>X, _ <span class="op">=</span> make_moons(n_samples, noise<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.FloatTensor(X)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">#Samples from a 2-dimensional standard normal</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>mean<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>covariance<span class="op">=</span>[[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]]</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> np.random.multivariate_normal(mean, covariance, n_samples)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> torch.FloatTensor(samples)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> TensorDataset(X, X)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>input_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>bottleneck_size<span class="op">=</span><span class="dv">2</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>hidden_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>layers<span class="op">=</span><span class="dv">5</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>Loss <span class="op">=</span> []</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>code_list<span class="op">=</span>[]</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>reconstructed_list<span class="op">=</span>[]</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="co">#hyperparameter: bandwidth</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>gamma<span class="op">=</span><span class="fl">5.5</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="co">#weight of Loss_mse</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>weight_list<span class="op">=</span>[<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>]</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> weight <span class="kw">in</span> weight_list:</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> autoencoder(input_size,bottleneck_size,hidden_size,layers)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>    Loss_epoch <span class="op">=</span> []</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> data <span class="kw">in</span> data_loader:</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>          inputs, _ <span class="op">=</span> data</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>          <span class="co">#Forward</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>          code,outputs <span class="op">=</span> model(inputs)</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>          <span class="co">#Loss_mse</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>          loss_mse <span class="op">=</span> criterion(outputs, inputs)</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>          <span class="co">#Loss_MMD</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>          kernel_XX_se <span class="op">=</span> se_kernel_custom(code, code,gamma<span class="op">=</span>gamma)</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>          kernel_YY_se <span class="op">=</span> se_kernel_custom(samples, samples,gamma<span class="op">=</span>gamma)</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>          kernel_XY_se <span class="op">=</span> se_kernel_custom(code, samples,gamma<span class="op">=</span>gamma)</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>          loss_MMD<span class="op">=</span>compute_mmd(kernel_XX_se, kernel_YY_se, kernel_XY_se)</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>          <span class="co">#Loss_total</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>          loss<span class="op">=</span>weight<span class="op">*</span>loss_mse<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>weight)<span class="op">*</span>loss_MMD</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>          <span class="co">#Backward</span></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>          optimizer.zero_grad()</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>          loss.backward()</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>          optimizer.step()</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>      Loss_epoch.append(loss.item())</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>    code,outputs<span class="op">=</span>model(X)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>    code_list.append(code)</span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>    reconstructed_list.append(outputs)</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a>    torch.save(model.state_dict(),<span class="st">&#39;model&#39;</span><span class="op">+</span><span class="bu">str</span>(weight) <span class="op">+</span><span class="st">&#39;.pth&#39;</span>)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>    Loss.append(Loss_epoch)</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:582}"
id="uxBVcFILlZbM" data-outputId="2e0446dc-9b5e-495d-9cd8-0e44f76daa51">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, weight <span class="kw">in</span> <span class="bu">enumerate</span>(weight_list):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(num_epochs), Loss[i], label<span class="op">=</span><span class="ss">f&quot;weight: </span><span class="sc">{</span>weight<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39; Loss for Different Weights&#39;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;loss: &#39;</span>,<span class="bu">str</span>(Loss[<span class="op">-</span><span class="dv">1</span>][<span class="op">-</span><span class="dv">1</span>]))</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/9aff0bc466ddd28156141d599d83210fae3d11d3.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>loss:  0.03924436494708061
</code></pre>
</div>
</div>
<div class="cell markdown" id="D4U70VON4kDZ">
<p>#Visualize the reconstructed vs. original data, and the code
distribution. Check that the reconstruction error is much less than what
you got with a bottleneck of size 1. Generate synthetic data by passing
standard normal samples through the decoder and visualize their quality.
Comment on your findings.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="_fmTr2A1sZ8x" data-outputId="f77d83ea-6d30-4dda-d051-fb57378fdf09">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    reconstructed_data<span class="op">=</span>reconstructed_list[i].detach().numpy()</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    ax.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Weight (MSE)=&#39;</span><span class="op">+</span><span class="bu">str</span>(weight_list[i]))</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.2</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Reconstructed Data vs Original Data&#39;</span>, y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/f2a943ee53e34a6d883c3d5825c533abb96732e4.png" /></p>
</div>
</div>
<div class="cell markdown" id="DAPuPwIEP41M">
<p>#Comment 1.Here we set different weights of MSE loss. The MSE loss
measures the difference between reconstructed and original data while
MMD loss measures the difference between code distribution and a 2D
normal distribution, so as expected, the reconstruction will be better
when the weight of MSE loss increases.</p>
<p>2.Compared to the bottleneck=1, this model is much better. The
reconstructed dataset is almost fully overlapped with the original
dataset, that's because bottleneck=1 can only reconstruct data in one
dimension while bottleneck=2 can reconstruct in two dimension.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:871}"
id="mfDXO2P3wdkZ" data-outputId="e910e7b2-ad83-4c2f-8c33-e3df3bdf51c5">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    code<span class="op">=</span>code_list[i].detach().numpy()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    hist<span class="op">=</span>ax.hist2d(x<span class="op">=</span>code[:,<span class="dv">0</span>], y<span class="op">=</span>code[:,<span class="dv">1</span>], bins<span class="op">=</span><span class="dv">20</span>, cmap<span class="op">=</span><span class="st">&#39;plasma&#39;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    fig.colorbar(hist[<span class="dv">3</span>], ax<span class="op">=</span>ax)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Weight (MSE)=&#39;</span><span class="op">+</span><span class="bu">str</span>(weight_list[i]))</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.2</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Histogram of the Code Distribution&#39;</span>, y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/8cd566724abb2a87effadf4b47af397af7cb9fa2.png" /></p>
</div>
</div>
<div class="cell markdown" id="Bv73HvHRUg-9">
<p>#Comment: According to the histogram of code distribution,we can see
that when the weight are 0.4 and 0.6, the distribution are more similar
to the 2D standard normal distribution. So we can expect the
reconstruction will be better with these two weight.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:780}"
id="UIDtBGy-1hON" data-outputId="ebee5015-d834-44b9-dc23-3350efc5331b">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>,squeeze<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axs.flat):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    loaded_state_dict <span class="op">=</span> torch.load(<span class="st">&#39;model&#39;</span> <span class="op">+</span><span class="bu">str</span>(weight_list[i]) <span class="op">+</span><span class="st">&#39;.pth&#39;</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(loaded_state_dict)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    reconstructed_data <span class="op">=</span> model.decode_function(samples).detach().numpy()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],label<span class="op">=</span><span class="st">&#39;Original Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    ax.scatter(reconstructed_data[:,<span class="dv">0</span>],reconstructed_data[:,<span class="dv">1</span>], label<span class="op">=</span><span class="st">&#39;Reconstructed Data&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Weight (MSE)=&#39;</span><span class="op">+</span><span class="bu">str</span>(weight_list[i]))</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=-</span><span class="fl">0.2</span>, right<span class="op">=</span><span class="fl">1.2</span>, top<span class="op">=</span><span class="fl">1.3</span>, bottom<span class="op">=</span><span class="dv">0</span>, wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Reconstructed Data vs Original Data&#39;</span>, y<span class="op">=</span><span class="fl">1.5</span>,fontsize<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/b2d1337edfc990598135263b8f2e30f897fce062.png" /></p>
</div>
</div>
<div class="cell markdown" id="O-MTIo71VjpS">
<p>#Comment 1.When the weight is too small, the code will focus to fit
the normal distribution and ignore the reconstruction accuracy. When the
weight is too big, the code distribution will be far from normal
distribution, so samples from normal distribution can't represent the
code, which will cause great difference in reconstruction.</p>
<p>2.The bandwidth of kernal is also important. After many experiments
we chose 5.5 as the bandwidth. When the value is smaller than 1 or
bigger than 10, the reocnstruction will be quite bad.</p>
</div>
<div class="cell markdown" id="7b43710b">
<p>Task 3</p>
</div>
<div class="cell code" id="s3FraFDCuMxb">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons, load_digits</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray <span class="im">import</span> tune</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray <span class="im">import</span> train, tune</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search.bayesopt <span class="im">import</span> BayesOptSearch</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search.optuna <span class="im">import</span> OptunaSearch</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search <span class="im">import</span> ConcurrencyLimiter</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>  sklearn.mixture <span class="im">import</span> GaussianMixture <span class="im">as</span> GMM</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier <span class="im">as</span> RFC</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.experimental <span class="im">import</span> enable_halving_search_cv</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> HalvingGridSearchCV</span></code></pre></div>
</div>
<div class="cell code" id="fdbc5644">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AutoEncoder(nn.Module):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, bottleneck_size, hidden_size, layers):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> input_size</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottleneck_size <span class="op">=</span> bottleneck_size</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> layers</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layers_encoder <span class="op">=</span> []</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layers_decoder <span class="op">=</span> []</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_layer <span class="op">=</span> nn.Linear(input_size, hidden_size)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(hidden_size, input_size)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottleneck_layer <span class="op">=</span> nn.Linear(bottleneck_size, bottleneck_size)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layers_decoder.append(nn.Linear(bottleneck_size, hidden_size))</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layers <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hidden_layers_encoder.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hidden_layers_encoder.append(nn.ReLU())</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hidden_layers_decoder.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hidden_layers_decoder.append(nn.ReLU())</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layers_encoder.append(nn.Linear(hidden_size, bottleneck_size))</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.Sequential(<span class="va">self</span>.input_layer,</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>                                   <span class="op">*</span><span class="va">self</span>.hidden_layers_encoder,</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>                                   <span class="va">self</span>.bottleneck_layer)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decoder <span class="op">=</span> nn.Sequential(<span class="op">*</span><span class="va">self</span>.hidden_layers_decoder,</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>                                   <span class="va">self</span>.output_layer)</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(<span class="va">self</span>.encoder, <span class="va">self</span>.decoder)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, x):</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.encoder(x)</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, z):</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.decoder(z)</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.decode(<span class="va">self</span>.encode(x))</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_loss(<span class="va">self</span>, X):</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>        error_type <span class="op">=</span> nn.MSELoss()</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>        reconstructed <span class="op">=</span> <span class="va">self</span>.forward(X)</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> error_type(reconstructed, X)</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_autoencoder(<span class="va">self</span>, X_train, ts_size, epochs, lr<span class="op">=</span><span class="fl">.01</span>):</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> torch.randperm(<span class="bu">len</span>(X_train))[:ts_size]</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>            X_train <span class="op">=</span> X_train[indices]</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>            error_type <span class="op">=</span> nn.MSELoss()</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>            optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>            losses <span class="op">=</span> []</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> <span class="va">self</span>.calculate_loss(X_train)</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>                losses.append(loss)</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>, losses</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" id="yX7F3cHfyzy_">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> import_data(noise<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">True</span>, n_test<span class="op">=</span><span class="fl">0.5</span>, name<span class="op">=</span><span class="st">&quot;moons&quot;</span>, n_samples <span class="op">=</span> <span class="dv">2000</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">&quot;moons&quot;</span>:</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        data, _ <span class="op">=</span> make_moons(noise<span class="op">=</span>noise, random_state<span class="op">=</span>random_state, shuffle<span class="op">=</span>shuffle, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        X_train, X_test<span class="op">=</span> train_test_split(data, test_size<span class="op">=</span>n_test, random_state<span class="op">=</span>random_state)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.FloatTensor(X_train), torch.FloatTensor(X_test), <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">&quot;digits&quot;</span>:</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        data, labels <span class="op">=</span> load_digits(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.reshape((<span class="bu">len</span>(data), <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span>  np.random.normal(<span class="dv">0</span>, noise <span class="op">*</span> data.<span class="bu">max</span>(), data.shape)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(data, labels, test_size<span class="op">=</span>n_test, random_state<span class="op">=</span>random_state)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.FloatTensor(X_train), torch.FloatTensor(X_test), torch.FloatTensor(Y_train), torch.FloatTensor(Y_test)</span></code></pre></div>
</div>
<div class="cell code" id="bA9Efed408LK">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> import_data(noise<span class="op">=</span><span class="dv">0</span>, random_state<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">True</span>, n_test<span class="op">=</span><span class="fl">0.5</span>, name<span class="op">=</span><span class="st">&quot;moons&quot;</span>, n_samples <span class="op">=</span> <span class="dv">2000</span>):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">&quot;moons&quot;</span>:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        data, _ <span class="op">=</span> make_moons(noise<span class="op">=</span>noise, random_state<span class="op">=</span>random_state, shuffle<span class="op">=</span>shuffle, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>        X_train, X_test<span class="op">=</span> train_test_split(data, test_size<span class="op">=</span>n_test, random_state<span class="op">=</span>random_state)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.FloatTensor(X_train), torch.FloatTensor(X_test), <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">&quot;digits&quot;</span>:</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        data, labels <span class="op">=</span> load_digits(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.reshape((<span class="bu">len</span>(data), <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span>  np.random.normal(<span class="dv">0</span>, noise <span class="op">*</span> data.<span class="bu">max</span>(), data.shape)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(data, labels, test_size<span class="op">=</span>n_test, random_state<span class="op">=</span>random_state)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.FloatTensor(X_train), torch.FloatTensor(X_test), torch.FloatTensor(Y_train), torch.FloatTensor(Y_test)</span></code></pre></div>
</div>
<div class="cell code" id="01d2e7fc">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, Y_train, Y_test <span class="op">=</span> import_data(noise<span class="op">=</span><span class="fl">0.1</span>, n_test<span class="op">=</span><span class="fl">0.5</span>,  name<span class="op">=</span><span class="st">&quot;digits&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" id="eeebb4fc">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> autoencoder_as_function_of_hyperparameters(config):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    auto, _ <span class="op">=</span> AutoEncoder(config[<span class="st">&quot;input_size&quot;</span>], config[<span class="st">&quot;bottleneck_size&quot;</span>],</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>                    config[<span class="st">&quot;hidden_size&quot;</span>], config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>                           config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>                           config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                           config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    loss_func <span class="op">=</span> nn.MSELoss()</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="bu">float</span>(loss_func(auto.forward(X_test), X_test).detach().numpy())</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    metric <span class="op">=</span> {<span class="st">&quot;loss&quot;</span>: loss }</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    ray.train.report(metric</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>       )</span></code></pre></div>
</div>
<div class="cell code" id="e075fd49"
data-outputId="efdc11cc-4553-4ba0-eeeb-7dd715869c87"
data-scrolled="true">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.schedulers <span class="im">import</span> ASHAScheduler</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search.ax <span class="im">import</span> AxSearch</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> opt(config):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    ax_search <span class="op">=</span> AxSearch()</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    algo <span class="op">=</span> OptunaSearch()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    algo <span class="op">=</span> ConcurrencyLimiter(algo, max_concurrent<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    tuner <span class="op">=</span> tune.Tuner(</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        autoencoder_as_function_of_hyperparameters,</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        tune_config<span class="op">=</span>tune.TuneConfig(</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>            scheduler<span class="op">=</span>ASHAScheduler(),</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>            search_alg<span class="op">=</span>algo,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>            metric<span class="op">=</span><span class="st">&quot;loss&quot;</span>,</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>            mode<span class="op">=</span><span class="st">&quot;min&quot;</span>,</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>            num_samples<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        param_space<span class="op">=</span>config,</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> tuner.fit()</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result.get_best_result().config</span></code></pre></div>
<div class="output display_data">
<div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2023-11-21 20:55:08</td></tr>
<tr><td>Running for: </td><td>00:00:28.26        </td></tr>
<tr><td>Memory:      </td><td>8.6/15.9 GiB       </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: -0.025325778871774673<br>Logical resource usage: 3.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
    </div>
    
  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name                                         </th><th>status    </th><th>loc            </th><th style="text-align: right;">  bottleneck_size</th><th style="text-align: right;">  epochs</th><th style="text-align: right;">  hidden_size</th><th style="text-align: right;">  input_size</th><th style="text-align: right;">  layers</th><th style="text-align: right;">   lr</th><th style="text-align: right;">  ts_size</th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">      loss</th></tr>
</thead>
<tbody>
<tr><td>autoencoder_as_function_of_hyperparameters_3f347f6c</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">      10</td><td style="text-align: right;">          110</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      900</td><td style="text-align: right;">     1</td><td style="text-align: right;">       1.40153  </td><td style="text-align: right;">0.180316  </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_924a189f</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     110</td><td style="text-align: right;">          110</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">     1100</td><td style="text-align: right;">     1</td><td style="text-align: right;">       1.67553  </td><td style="text-align: right;">0.0340025 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_8466c332</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          120</td><td style="text-align: right;">           2</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      600</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.211002 </td><td style="text-align: right;">0.100117  </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_78871274</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     110</td><td style="text-align: right;">           80</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      100</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.350002 </td><td style="text-align: right;">0.0726774 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_4066187c</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">      10</td><td style="text-align: right;">           10</td><td style="text-align: right;">           2</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      200</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.016001 </td><td style="text-align: right;">1.01011   </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_08e7e1d1</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          140</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       2.97508  </td><td style="text-align: right;">0.00988839</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_cb9f9ca5</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">           70</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1600</td><td style="text-align: right;">     1</td><td style="text-align: right;">       2.8787   </td><td style="text-align: right;">0.0382183 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_b7cf6ee9</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     110</td><td style="text-align: right;">           70</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      400</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.578001 </td><td style="text-align: right;">0.0730335 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_f8b2b885</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">      10</td><td style="text-align: right;">           70</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.105998 </td><td style="text-align: right;">0.475411  </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_b78ad8d0</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">      60</td><td style="text-align: right;">           30</td><td style="text-align: right;">           2</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      600</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.0770013</td><td style="text-align: right;">0.143556  </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_b50ea9d2</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     110</td><td style="text-align: right;">           70</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      200</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.35     </td><td style="text-align: right;">0.025526  </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_f2d7453d</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          140</td><td style="text-align: right;">           2</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       1.20603  </td><td style="text-align: right;">0.0548178 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_e8b116b6</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          140</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       2.31652  </td><td style="text-align: right;">0.0247252 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_0094a67c</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">      60</td><td style="text-align: right;">           50</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      800</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.400032 </td><td style="text-align: right;">0.0668663 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_481dbf57</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          140</td><td style="text-align: right;">           2</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       2.33206  </td><td style="text-align: right;">0.0291348 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_5896bf7f</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          140</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       2.58408  </td><td style="text-align: right;">0.0222281 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_9c20e088</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">           40</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.57514  </td><td style="text-align: right;">0.04003   </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_adb3c017</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          130</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      300</td><td style="text-align: right;">     1</td><td style="text-align: right;">       1.63356  </td><td style="text-align: right;">0.0221027 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_ef7bdd6e</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">           20</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">     1400</td><td style="text-align: right;">     1</td><td style="text-align: right;">       0.633536 </td><td style="text-align: right;">0.0476101 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_6009c10c</td><td>TERMINATED</td><td>127.0.0.1:19252</td><td style="text-align: right;">                1</td><td style="text-align: right;">     160</td><td style="text-align: right;">          130</td><td style="text-align: right;">           2</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      300</td><td style="text-align: right;">     1</td><td style="text-align: right;">       1.65002  </td><td style="text-align: right;">0.0121594 </td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>

</div>
<div class="output stream stderr">
<pre><code>2023-11-21 20:55:10,745	INFO tune.py:1045 -- Total run time: 30.20 seconds (28.25 seconds for the tuning loop).
</code></pre>
</div>
</div>
<div class="cell code" id="0a3bfd91"
data-outputId="4522d62a-14af-4f7a-af88-a39e2b74ad2f"
data-scrolled="true">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>config<span class="op">=</span>{<span class="st">&quot;input_size&quot;</span>:  tune.choice([<span class="dv">64</span>]), <span class="st">&quot;bottleneck_size&quot;</span>:  tune.choice([<span class="dv">8</span>]),</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;hidden_size&quot;</span>:  tune.choice([x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>, <span class="dv">600</span>, <span class="dv">40</span>)]),</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;layers&quot;</span>:  tune.choice([x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>)]),</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;ts_size&quot;</span>:  tune.choice([x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>, <span class="dv">1500</span>, <span class="dv">100</span>)]),</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;epochs&quot;</span>:  tune.choice([x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">400</span>, <span class="dv">600</span>)]),</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;lr&quot;</span>: tune.choice([<span class="fl">0.01</span>, <span class="fl">0.001</span>])}</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>good_config <span class="op">=</span> opt(config)</span></code></pre></div>
<div class="output display_data">
<div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3>Tune Status</h3>
      <table>
<tbody>
<tr><td>Current time:</td><td>2023-11-21 13:20:32</td></tr>
<tr><td>Running for: </td><td>00:01:47.43        </td></tr>
<tr><td>Memory:      </td><td>8.4/15.9 GiB       </td></tr>
</tbody>
</table>
    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3>System Info</h3>
      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: -5.922897815704346<br>Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
    </div>
    
  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3>Trial Status</h3>
    <table>
<thead>
<tr><th>Trial name                                         </th><th>status    </th><th>loc            </th><th style="text-align: right;">  bottleneck_size</th><th style="text-align: right;">  epochs</th><th style="text-align: right;">  hidden_size</th><th style="text-align: right;">  input_size</th><th style="text-align: right;">  layers</th><th style="text-align: right;">   lr</th><th style="text-align: right;">  ts_size</th><th style="text-align: right;">  iter</th><th style="text-align: right;">  total time (s)</th><th style="text-align: right;">    loss</th></tr>
</thead>
<tbody>
<tr><td>autoencoder_as_function_of_hyperparameters_93610e34</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     461</td><td style="text-align: right;">          180</td><td style="text-align: right;">          64</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      900</td><td style="text-align: right;">     1</td><td style="text-align: right;">        20.4079 </td><td style="text-align: right;"> 9.82533</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_85ac6e91</td><td>TERMINATED</td><td>127.0.0.1:4460 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     432</td><td style="text-align: right;">          140</td><td style="text-align: right;">          64</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      600</td><td style="text-align: right;">     1</td><td style="text-align: right;">         2.61391</td><td style="text-align: right;"> 6.63504</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_665f7ce2</td><td>TERMINATED</td><td>127.0.0.1:4460 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     571</td><td style="text-align: right;">          340</td><td style="text-align: right;">          64</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      300</td><td style="text-align: right;">     1</td><td style="text-align: right;">        18.9116 </td><td style="text-align: right;">18.8184 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_0d5f52f0</td><td>TERMINATED</td><td>127.0.0.1:3344 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     598</td><td style="text-align: right;">          340</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      400</td><td style="text-align: right;">     1</td><td style="text-align: right;">        15.3265 </td><td style="text-align: right;">19.1949 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_5688780e</td><td>TERMINATED</td><td>127.0.0.1:16032</td><td style="text-align: right;">                8</td><td style="text-align: right;">     403</td><td style="text-align: right;">          260</td><td style="text-align: right;">          64</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1100</td><td style="text-align: right;">     1</td><td style="text-align: right;">         4.25358</td><td style="text-align: right;"> 6.51319</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_e06e1dad</td><td>TERMINATED</td><td>127.0.0.1:16032</td><td style="text-align: right;">                8</td><td style="text-align: right;">     528</td><td style="text-align: right;">          580</td><td style="text-align: right;">          64</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1100</td><td style="text-align: right;">     1</td><td style="text-align: right;">         8.38031</td><td style="text-align: right;"> 6.46688</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_98f248d1</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     423</td><td style="text-align: right;">          140</td><td style="text-align: right;">          64</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">      700</td><td style="text-align: right;">     1</td><td style="text-align: right;">         7.34479</td><td style="text-align: right;">11.1844 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_dc426a63</td><td>TERMINATED</td><td>127.0.0.1:4460 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     453</td><td style="text-align: right;">          340</td><td style="text-align: right;">          64</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">     1200</td><td style="text-align: right;">     1</td><td style="text-align: right;">        60.7727 </td><td style="text-align: right;">15.4517 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_8a9184e6</td><td>TERMINATED</td><td>127.0.0.1:3344 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     583</td><td style="text-align: right;">          460</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">     1000</td><td style="text-align: right;">     1</td><td style="text-align: right;">        50.4972 </td><td style="text-align: right;">18.2335 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_d0156670</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     592</td><td style="text-align: right;">          140</td><td style="text-align: right;">          64</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      500</td><td style="text-align: right;">     1</td><td style="text-align: right;">        11.0299 </td><td style="text-align: right;">12.7728 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_59c33044</td><td>TERMINATED</td><td>127.0.0.1:16032</td><td style="text-align: right;">                8</td><td style="text-align: right;">     511</td><td style="text-align: right;">          260</td><td style="text-align: right;">          64</td><td style="text-align: right;">       4</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      300</td><td style="text-align: right;">     1</td><td style="text-align: right;">        16.3249 </td><td style="text-align: right;">10.3347 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_90be755a</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     403</td><td style="text-align: right;">          180</td><td style="text-align: right;">          64</td><td style="text-align: right;">       3</td><td style="text-align: right;">0.01 </td><td style="text-align: right;">     1300</td><td style="text-align: right;">     1</td><td style="text-align: right;">        13.2834 </td><td style="text-align: right;">18.2207 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_e69ea8df</td><td>TERMINATED</td><td>127.0.0.1:16032</td><td style="text-align: right;">                8</td><td style="text-align: right;">     451</td><td style="text-align: right;">          380</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      700</td><td style="text-align: right;">     1</td><td style="text-align: right;">        22.7162 </td><td style="text-align: right;"> 3.99564</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_4d65cfbb</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     522</td><td style="text-align: right;">          580</td><td style="text-align: right;">          64</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1100</td><td style="text-align: right;">     1</td><td style="text-align: right;">         8.84769</td><td style="text-align: right;"> 6.41723</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_28918c19</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     439</td><td style="text-align: right;">          580</td><td style="text-align: right;">          64</td><td style="text-align: right;">       1</td><td style="text-align: right;">0.001</td><td style="text-align: right;">     1100</td><td style="text-align: right;">     1</td><td style="text-align: right;">         7.58648</td><td style="text-align: right;"> 6.41221</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_aca2743d</td><td>TERMINATED</td><td>127.0.0.1:16032</td><td style="text-align: right;">                8</td><td style="text-align: right;">     437</td><td style="text-align: right;">          380</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      800</td><td style="text-align: right;">     1</td><td style="text-align: right;">        24.131  </td><td style="text-align: right;"> 4.1238 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_61624944</td><td>TERMINATED</td><td>127.0.0.1:19152</td><td style="text-align: right;">                8</td><td style="text-align: right;">     505</td><td style="text-align: right;">          380</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      800</td><td style="text-align: right;">     1</td><td style="text-align: right;">        27.7941 </td><td style="text-align: right;"> 3.95968</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_a48eb92f</td><td>TERMINATED</td><td>127.0.0.1:3344 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     575</td><td style="text-align: right;">          380</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      700</td><td style="text-align: right;">     1</td><td style="text-align: right;">        26.4617 </td><td style="text-align: right;"> 4.16253</td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_0695e707</td><td>TERMINATED</td><td>127.0.0.1:4460 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     439</td><td style="text-align: right;">          380</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      100</td><td style="text-align: right;">     1</td><td style="text-align: right;">         4.95181</td><td style="text-align: right;">10.6474 </td></tr>
<tr><td>autoencoder_as_function_of_hyperparameters_d8b66fbe</td><td>TERMINATED</td><td>127.0.0.1:4460 </td><td style="text-align: right;">                8</td><td style="text-align: right;">     466</td><td style="text-align: right;">          220</td><td style="text-align: right;">          64</td><td style="text-align: right;">       2</td><td style="text-align: right;">0.001</td><td style="text-align: right;">      700</td><td style="text-align: right;">     1</td><td style="text-align: right;">         9.05798</td><td style="text-align: right;"> 4.45496</td></tr>
</tbody>
</table>
  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>

</div>
<div class="output stream stderr">
<pre><code>2023-11-21 13:20:32,944	INFO tune.py:1045 -- Total run time: 107.46 seconds (107.42 seconds for the tuning loop).
</code></pre>
</div>
</div>
<div class="cell markdown" id="a4c66c21">
<p>The plot below shows the MSE reconstruction error vs the parameters.
For hidden size, the size of the ts and the number of epochs, the error
seems to stagnate. So increasing them after some point wont change
anything. Some local optima can be spotted for the number of layers and
the learning rate. Increasing the bottle neck size decreases the error
drasticly.</p>
</div>
<div class="cell code" id="0293eb20"
data-outputId="0b8867a0-2822-485a-afbf-a8fb05b1c9c4">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>generate_plots()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/1e3dafe17016c5158856fc1f61ccd8a48d5e366f.png" /></p>
</div>
</div>
<div class="cell markdown" id="3ece81cd">
<p>The plot below shows the averaged error vs the bottleneck size. The
error decays and will propably stagnate after dim(z) &gt; 20.</p>
</div>
<div class="cell code" id="e11be39b"
data-outputId="33f6df16-8e75-488a-fc9a-190d1b894c4b">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss_vs_hidden_size():</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> []</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">20</span>):</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(i)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        auto, _ <span class="op">=</span>  AutoEncoder(good_config[<span class="st">&quot;input_size&quot;</span>], i,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>                                    good_config[<span class="st">&quot;hidden_size&quot;</span>], good_config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        loss.append(<span class="bu">float</span>(auto.calculate_loss(X_test).detach().numpy()))</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    losses.append(np.array(loss))</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>threads <span class="op">=</span> []</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    thread <span class="op">=</span> threading.Thread(target<span class="op">=</span>plot_loss_vs_hidden_size)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    thread.start()</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    threads.append(thread)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>[t.join() <span class="cf">for</span> t <span class="kw">in</span> threads]</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f&quot;Size of hidden layer vs MSE Reconstruction, averaged n=</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;size of hidden layer&quot;</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MSE Reconstruction&quot;</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> np.array([<span class="dv">0</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(losses[<span class="dv">0</span>]))])</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(loss.shape)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> losses:</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> np.add(loss, l)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> loss<span class="op">/</span>n</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>plt.plot([x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(loss))], loss)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
3
3
3
3
3
3
3
3
3
3
4
4
4
4
4
4
4
4
4
4
5
5
5
5
5
5
5
5
5
5
6
6
6
6
6
6
6
6
6
6
7
7
7
7
7
7
7
8
8
7
7
7
8
8
8
8
9
9
8
8
8
8
9
9
10
10
9
9
9
9
9
9
10
10
11
11
10
10
10
10
10
11
10
11
12
12
11
11
11
12
11
11
11
12
13
13
12
12
12
13
13
12
12
12
14
14
13
13
13
14
14
13
13
13
15
15
14
14
14
15
15
16
16
14
14
14
15
15
16
16
15
17
17
15
15
15
16
16
17
17
18
18
16
16
16
16
17
17
19
19
18
18
17
17
17
17
18
18
19
19
18
18
18
18
19
19
19
19
19
19
(19,)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="31">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x231f43b9b10&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/c37fd330801fd454d3443e6208c3186e1a490a98.png" /></p>
</div>
</div>
<div class="cell markdown" id="f7d438ff">
<p>The plot belows shows randomly selected digits from the data set and
its reconstruction for different dim(z). It can be observed that with
increasing dim(z), the reconstruction gets better. A simple explanation
would be, that 2 dimensional codes are not sufficient to encode all the
information per sample.</p>
</div>
<div class="cell code" id="350c807b"
data-outputId="d3cde0fc-b128-41c4-dc8f-98e65334e464">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="ss">f&quot;Reconstruction with different code dimension&quot;</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>j <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.choice([i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X_test))])</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> X_test[x]</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>]:</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    auto, _ <span class="op">=</span>  AutoEncoder(good_config[<span class="st">&quot;input_size&quot;</span>], i,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>                                    good_config[<span class="st">&quot;hidden_size&quot;</span>], good_config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>, j].imshow(x.reshape(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>, j].set_title(<span class="st">&quot;True data&quot;</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>, j].imshow(auto.forward(x).detach().numpy().reshape(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>, j].set_title(<span class="st">&quot;Reconstructed data&quot;</span>)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>, j].set_xlabel(<span class="ss">f&quot;dim(code) = </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    j <span class="op">+=</span> <span class="dv">1</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/b47f44ba293775eac875990892b2d6a5266cad2f.png" /></p>
</div>
</div>
<div class="cell code" id="6f2551ce">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell markdown" id="a70defcb">
<p>The plot below shows, that the autoencoder does not yield the exact
same results for the same parameters. Therefore there is always some
variation in the results. This is due to random initialization of the
weights and the random order and selection of the data set used for
training.</p>
</div>
<div class="cell code" id="43ac2e0e"
data-outputId="1b600438-6c13-4748-a828-42b85e7072dc">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f&quot;Trial vs MSE Reconstruction&quot;</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of trial&quot;</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MSE Reconstruction&quot;</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> []</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    auto, _ <span class="op">=</span>  AutoEncoder(good_config[<span class="st">&quot;input_size&quot;</span>],good_config[<span class="st">&quot;bottleneck_size&quot;</span>] ,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>                                    good_config[<span class="st">&quot;hidden_size&quot;</span>], good_config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>                                           good_config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    loss.append(<span class="bu">float</span>(auto.calculate_loss(X_test).detach().numpy()))</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.plot(loss)</span></code></pre></div>
<div class="output execute_result" data-execution_count="33">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x231f44664d0&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/e3046409ce863d71ca354a73d29abccb8605fd8e.png" /></p>
</div>
</div>
<div class="cell code" id="d3cd0f71">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_z(X, auto<span class="op">=</span><span class="va">None</span>, bs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> auto <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>        auto, _ <span class="op">=</span>  AutoEncoder(good_config[<span class="st">&quot;input_size&quot;</span>],(good_config[<span class="st">&quot;bottleneck_size&quot;</span>] <span class="cf">if</span> bs <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> bs),</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>                                        good_config[<span class="st">&quot;hidden_size&quot;</span>], good_config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>                                               good_config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>                                               good_config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>                                               good_config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> auto, auto.encode(X)</span></code></pre></div>
</div>
<div class="cell code" id="0de3a581">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" id="6f9a5fda">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_synthetic_data(bs, k):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> bs <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>        auto, Z_train <span class="op">=</span> get_z(X_test, bs<span class="op">=</span>bs)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>        _, Z_test <span class="op">=</span> get_z(X_train, auto<span class="op">=</span>auto)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>        Z_train <span class="op">=</span> Z_test.detach().numpy()</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>        Z_test <span class="op">=</span> Z_test.detach().numpy()</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> []</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">50</span>):</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>            scores.append(GMM(n_components <span class="op">=</span> n).fit(Z_train).bic(Z_test))</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        gmm <span class="op">=</span> GMM(n_components<span class="op">=</span> np.argmin(scores)).fit(Z_test)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.FloatTensor(gmm.sample(k<span class="op">**</span><span class="dv">2</span>)[<span class="dv">0</span>])</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        synthetic_data <span class="op">=</span> auto.decode(samples)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>        synthetic_data <span class="op">=</span> X_test</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(k,k)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k<span class="op">**</span><span class="dv">2</span>):</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>        ax.flatten()[i].imshow(synthetic_data[i].detach().numpy().reshape(<span class="dv">8</span>,<span class="dv">8</span>))</span></code></pre></div>
</div>
<div class="cell markdown" id="ece5bc1c">
<p>Here 4 by 4 codes get drawn from the gmm and reconstructed. First for
dim(z) = 2, dim(z) = 4, dim(z) = 8 and 16 samples from the original data
set for comparision. It can be observerd that with increasing code
dimension, the synthetic numbers get more readable but also the
background gets more noisy.</p>
</div>
<div class="cell code" id="a4e6589a"
data-outputId="3cbc7c6a-49aa-447a-ba64-5aa6a4b3c0b0">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>plot_synthetic_data(<span class="dv">2</span>, <span class="dv">4</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/2204bf2e2ac6f3345bbf47e08cf1ed056937d57b.png" /></p>
</div>
</div>
<div class="cell code" id="2d3deb65"
data-outputId="689823c3-3bfd-4ad7-96d5-da735c5a7472">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>plot_synthetic_data(<span class="dv">4</span>, <span class="dv">4</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/7acbd7a7f77b67b4b1e3953fb0d1fa0ebe6a72db.png" /></p>
</div>
</div>
<div class="cell code" id="abdbb5a5"
data-outputId="bff4b712-1680-4d61-c668-e7511abbf19e">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>plot_synthetic_data(<span class="dv">8</span>, <span class="dv">4</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/6a914a1b307035327604d9f27c3674f22ea08ca9.png" /></p>
</div>
</div>
<div class="cell code" id="925474b8"
data-outputId="ac1065c1-ec57-4d5e-e98c-d22f125956ba">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>plot_synthetic_data(<span class="dv">0</span>, <span class="dv">4</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/9d9ed706841580ff92ca5c2e26ad88ad5e2f4332.png" /></p>
</div>
</div>
<div class="cell markdown" id="a3eb621f">
<p>The plot below shows the distribution of the codes for dim(z) = 2. It
is observable that most of the digits overlap. Hence some digits are too
similar to each other in code space. This shows that 2 dimensional codes
are not enough to reliably seperate the digits.</p>
</div>
<div class="cell code" id="89e7e272"
data-outputId="0bd9c71f-eac6-4649-9cb5-65c6e65a4e4c">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    _, z <span class="op">=</span> get_z(X_test[np.where(Y_test <span class="op">==</span> i)], bs<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> z.detach().numpy()</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    plt.scatter(z.T[<span class="dv">0</span>], z.T[<span class="dv">1</span>], label<span class="op">=</span><span class="ss">f&quot;Digit </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code></pre></div>
<div class="output execute_result" data-execution_count="40">
<pre><code>&lt;matplotlib.legend.Legend at 0x23203c9c7d0&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/7384cbd93d86ad40e0795583f62623984e171168.png" /></p>
</div>
</div>
<div class="cell code" id="684c14fb">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_rfc(data, targets):</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    p_grid <span class="op">=</span> {<span class="st">&quot;n_estimators&quot;</span>:[<span class="dv">100</span> <span class="op">*</span> x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>)], <span class="st">&quot;criterion&quot;</span> : [<span class="st">&quot;gini&quot;</span>, <span class="st">&quot;entropy&quot;</span>, <span class="st">&quot;log_loss&quot;</span>],</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&quot;max_features&quot;</span>: [<span class="st">&quot;sqrt&quot;</span>, <span class="st">&quot;log2&quot;</span>, <span class="va">None</span>]}</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    rfc <span class="op">=</span> HalvingGridSearchCV(RFC(), p_grid, refit<span class="op">=</span><span class="va">True</span>, verbose<span class="op">=</span><span class="dv">1</span>, cv<span class="op">=</span><span class="dv">3</span>).fit(data, targets)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rfc.best_estimator_</span></code></pre></div>
</div>
<div class="cell code" id="1c3bcd05"
data-outputId="68ecea00-1a58-4c7b-dc74-e203d1ec0628">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>rfc <span class="op">=</span> train_rfc(X_train, Y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>n_iterations: 3
n_required_iterations: 4
n_possible_iterations: 3
min_resources_: 60
max_resources_: 898
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 36
n_resources: 60
Fitting 3 folds for each of 36 candidates, totalling 108 fits
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:425: FitFailedWarning: 
27 fits failed out of a total of 108.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score=&#39;raise&#39;.

Below are more details about the failures:
--------------------------------------------------------------------------------
27 fits failed with the following error:
Traceback (most recent call last):
  File &quot;C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py&quot;, line 732, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &quot;C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\base.py&quot;, line 1144, in wrapper
    estimator._validate_params()
  File &quot;C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\base.py&quot;, line 637, in _validate_params
    validate_parameter_constraints(
  File &quot;C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py&quot;, line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The &#39;n_estimators&#39; parameter of RandomForestClassifier must be an int in the range [1, inf). Got 0 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69210526 0.65877193 0.6754386         nan 0.69298246
 0.69385965 0.67631579        nan 0.57017544 0.62368421 0.60526316
        nan 0.70964912 0.6745614  0.69298246        nan 0.71052632
 0.67631579 0.67631579        nan 0.67368421 0.64035088 0.69210526
        nan 0.72894737 0.70964912 0.63947368        nan 0.70964912
 0.69298246 0.71052632        nan 0.63947368 0.65789474 0.63859649]
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.
  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1.]
  warnings.warn(
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>----------
iter: 1
n_candidates: 12
n_resources: 180
Fitting 3 folds for each of 12 candidates, totalling 36 fits
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69210526 0.65877193 0.6754386         nan 0.69298246
 0.69385965 0.67631579        nan 0.57017544 0.62368421 0.60526316
        nan 0.70964912 0.6745614  0.69298246        nan 0.71052632
 0.67631579 0.67631579        nan 0.67368421 0.64035088 0.69210526
        nan 0.72894737 0.70964912 0.63947368        nan 0.70964912
 0.69298246 0.71052632        nan 0.63947368 0.65789474 0.63859649
 0.89312618 0.89303202 0.90433145 0.89868173 0.88766478 0.89303202
 0.8873823  0.89877589 0.89312618 0.88747646 0.87052731 0.88182674]
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.
  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
  warnings.warn(
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>----------
iter: 2
n_candidates: 4
n_resources: 540
Fitting 3 folds for each of 4 candidates, totalling 12 fits
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.69210526 0.65877193 0.6754386         nan 0.69298246
 0.69385965 0.67631579        nan 0.57017544 0.62368421 0.60526316
        nan 0.70964912 0.6745614  0.69298246        nan 0.71052632
 0.67631579 0.67631579        nan 0.67368421 0.64035088 0.69210526
        nan 0.72894737 0.70964912 0.63947368        nan 0.70964912
 0.69298246 0.71052632        nan 0.63947368 0.65789474 0.63859649
 0.89312618 0.89303202 0.90433145 0.89868173 0.88766478 0.89303202
 0.8873823  0.89877589 0.89312618 0.88747646 0.87052731 0.88182674
 0.95353818 0.94795158 0.95542106 0.95912477]
  warnings.warn(
C:\Users\Florian\anaconda3\Lib\site-packages\sklearn\model_selection\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.
  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1. nan  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
  warnings.warn(
</code></pre>
</div>
</div>
<div class="cell code" id="eb8c6f7f"
data-outputId="c1c01474-0192-4aad-968e-dfc1c11be747">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>rfc.score(X_test, Y_test)</span></code></pre></div>
<div class="output execute_result" data-execution_count="44">
<pre><code>0.9699666295884316</code></pre>
</div>
</div>
<div class="cell code" id="e87723c4">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reconstruction_quality():</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    j <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">8</span>]:</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>        auto, _ <span class="op">=</span>  AutoEncoder(good_config[<span class="st">&quot;input_size&quot;</span>],i,</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>                                            good_config[<span class="st">&quot;hidden_size&quot;</span>], good_config[<span class="st">&quot;layers&quot;</span>]).train_autoencoder(X_train,</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>                                                   good_config[<span class="st">&quot;ts_size&quot;</span>],</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>                                                   good_config[<span class="st">&quot;epochs&quot;</span>],</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>                                                   good_config[<span class="st">&quot;lr&quot;</span>])</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        reconstructed <span class="op">=</span> auto.forward(X_test).detach().numpy()</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> rfc.predict(reconstructed)</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        diff <span class="op">=</span> Y_test <span class="op">-</span> predictions</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">=</span> <span class="bu">len</span>(np.where(<span class="bu">abs</span>(diff) <span class="op">&lt;=</span> <span class="fl">1E-8</span>)[<span class="dv">0</span>])</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>        false <span class="op">=</span> <span class="bu">len</span>(Y_test) <span class="op">-</span> correct</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>        ax[j].bar([<span class="st">&quot;right&quot;</span>, <span class="st">&quot;wrong&quot;</span>], [correct, false])</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>        j <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" id="1db33365">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell markdown" id="f5e5feaf">
<p>To get an idea how well the autoencoder behaves, some data gets
reconstructed bz the autoencoder. Then a random forest classifier
classifies the reconstructed data. Those classifications get compared to
the labels of the original data. If the label and the RFCs prediction
match, the reconstruction is deemd successfull. Otherwhise the
reconstruction is flawed. The histogram below shows the results of this
procedure for different code dimentions (2, 4, 8) in this order. The
reconstruction quality gets better with increasing code dimension. This
is also observable on previous plots.</p>
</div>
<div class="cell code" id="2eade155"
data-outputId="d770e37a-0fdd-4671-fad2-a97334be2196">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>reconstruction_quality()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_6269b6bef29349959a8ffdc2dac3502d/92ec94e58c4a6d81a8e194666bb4753100203fb6.png" /></p>
</div>
</div>
<div class="cell code" id="dd696d29">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" id="7a57855f">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
